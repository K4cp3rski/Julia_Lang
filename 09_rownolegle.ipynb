{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "624b02c0",
   "metadata": {},
   "source": [
    "# Przetwarzanie równoległe\n",
    "\n",
    "W Julii mamy cztery typy obliczeń równoległych:\n",
    "\n",
    "1. Asynchroniczne zadania (`tasks`) - które mogą być zawieszane, przełączane, oczekiwać zakończenia przez inne zadania itp. Ściśle rzecz biorąc nie są to obliczenia równoległe, ale są takie kiedy zadania są wykonywane przez różne wątki\n",
    "2. Obliczenia wielowątkowe - zadania uruchamiane na wielu wątkach, na wielu procesorach, ale na tej samej maszynie, dzielące wspólną pamięć RAM\n",
    "3. Obliczenia rozproszone - obliczenia wykonywane na oddzielnych przestrzeniach pamięci na wielu procesorach lub komputerach\n",
    "4. Obliczenia na GPU\n",
    "\n",
    "Na zajęciach zajmiemy się przypadkami 1, 2 i 3. Obliczenia na GPU wymagają pewnych przygotowań oraz przede wszystkim posiadania odpowiedniego GPU (którego nie możemy zapewnić) zaintersowanych odsyłam [tu](https://juliagpu.org/)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3dc8bde",
   "metadata": {},
   "source": [
    "## 1. Zadania (tasks)\n",
    "\n",
    "Kawałek kodu (zwykle funkcja) może zostać zadaniem (`task`). W odróżnieniu od zwykłych funkcji mamy swobodę przełączania się między zadaniami w dowolnej kolejności. Typowym zastosowaniem jest np. komunikacja z zewnętrzem, czekanie na transfer danych itp. podczas którego możemy wykonywać inne czynności i przerwać je gdy zajdzie potrzeba.\n",
    "\n",
    "Zadanie tworzymy za pomocą makra `@task`, następujące wyrażenie (funkcja, itp.) zostanie zadaniem, ale nie zostanie uruchomione."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89a3f6bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = rand(1000)\n",
    "t = @task begin; sleep(2); println(\"t: \", length(filter(x -> x > 0.5, y))); end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5287d80",
   "metadata": {},
   "source": [
    "Zadanie uruchamiamy poleceniem `schedule`, zostanie ono uruchomione i program przejdzie do następnych poleceń. Jeżeli chemy od razu stworzyć i uruchomić zadanie możemy użyć polecenia `@async`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f7fd564",
   "metadata": {},
   "outputs": [],
   "source": [
    "schedule(t)\n",
    "println(\"main: \", length(filter(x -> x > 0.5, y)))\n",
    "@async begin; sleep(2); println(\"t2: done\"); end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77fef784",
   "metadata": {},
   "source": [
    "Jeżeli chcemy w którymś momencie zaczekać na zakończenie zadania, możemy użyć polecenia `wait(t)`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52cc7647",
   "metadata": {},
   "source": [
    "### Przykład\n",
    "\n",
    "Wyobraźmy sobie, że checmy sprawdzić jakie komputery odpowiadają na wywołanie w podsieci x.x.x.x/24, czyli np. 10.13.2.1-254. Użyjemy systemowego polecenia `ping`, których będziemy próbować wywołać komputer tylko jeden raz i czekać na odpowiedź co najwyżej 5 sekund. Polecenia zewnętrzne w Julii (podobnie jak w shellu) otaczane są odwrotnymi pojedynczymi cudczysłowami \\`. Polecenie można uruchomić funkcją `run`, albo jeżeli chcemy poznać odpowiedź `read`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a611337c",
   "metadata": {},
   "outputs": [],
   "source": [
    "read(`ping -c 1 -w 5 192.168.1.1`, String)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ee24ac2",
   "metadata": {},
   "source": [
    "W przypadku gdy dany adres nie odpowiada otrzymamy błąd, bo proces zwraca wynik różny niż zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e252a97",
   "metadata": {},
   "outputs": [],
   "source": [
    "read(`ping -c 1 -w 5 192.168.1.2`, String)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "238d4757",
   "metadata": {},
   "source": [
    "Skanowanie sieci kolejnymi wywołaniami może trwać długo - jeżeli na każdą odpowiedź czekamy maksymalnie 5 sekund i dopiero wtedy wysyłamy następny ping, to łącznie może to trwać ponad 20 minut (254 * 5 sekund). Możemy jednak uruchomić równolegle wiele procesów. Na koniec poczekamy aż wszystkie zadania skończą działanie i wyświetlimy listę adresów IP, które odpowiedziały."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eab3fb15",
   "metadata": {},
   "outputs": [],
   "source": [
    "function ping(ip)\n",
    "    try\n",
    "        s = read(`ping -c 1 -w 5 $ip`, String)\n",
    "        return s\n",
    "    catch err\n",
    "        return \"\"\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18710af9",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 254\n",
    "ip_tab = Array{String, 1}(undef, N)\n",
    "tasks = Array{Task, 1}()\n",
    "for i in 1:N\n",
    "    push!(tasks, @async ip_tab[i] = ping(\"192.168.1.$i\"))\n",
    "end\n",
    "\n",
    "for i in 1:N\n",
    "    wait(tasks[i])\n",
    "    if length(ip_tab[i]) > 0\n",
    "        println(\"192.168.1.$i\")\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bbfca8e",
   "metadata": {},
   "source": [
    "Podobny efekt możemy osiągnąć używając funkcji `asyncmap`, która jest odpowiednikiem `map`, ale zamiast uruchamiać funckje dla każdego elementu kolekcji, uruchomi zadania"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3333b0cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "asyncmap(x->ping(x), 1:N);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5392fbf",
   "metadata": {},
   "source": [
    "## Kanały (Channel)\n",
    "\n",
    "Kanał to kolejka FIFO o zadanej długości (lub \"nieskończona\"), której mogą używać różne zadania do komunikacji i wymiany danych.\n",
    "* Channel{T}(n) - typ T, długość n; domyślnie Any, 0 - kolejka bez bufora, długość Inf oznacza typemax(Int)\n",
    "* `put!` dodaje element do kolejki\n",
    "* `take!` zabiera element z kolejki\n",
    "* `fetch` czyta element z kolejki (bez zabierania)\\\n",
    "* jeżeli kanał jest pusty funkcja `take!` czeka aż pojawią się dane\n",
    "* jeżeli kanał jest pełny funkcja `put!` czeka aż pojawi się miejsce\n",
    "* `isready` sprawdza obecność jakiegokolwiek elementu w kolejce\n",
    "* `wait` czeka na pojawienie się elementu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1ebcb39",
   "metadata": {},
   "outputs": [],
   "source": [
    "using GRUtils\n",
    "using StatsBase\n",
    "\n",
    "function worker(id, data, stop)\n",
    "    while true\n",
    "        if isready(stop)\n",
    "            break\n",
    "        end\n",
    "        sleep(rand() * 0.1)\n",
    "        put!(data, id)\n",
    "    end\n",
    "    println(\"W-\", id, \" done\")\n",
    "end\n",
    "\n",
    "sigstop = Channel{Bool}(1)\n",
    "times = Channel{Int64}(Inf)\n",
    "tasks = Array{Task, 1}()\n",
    "N = 10\n",
    "\n",
    "println(\"Start\")\n",
    "\n",
    "for i in 1:N\n",
    "    push!(tasks, @async worker(i, times, sigstop))\n",
    "end\n",
    "\n",
    "sleep(5)\n",
    "println(\"Stop send\")\n",
    "put!(sigstop, true)\n",
    "\n",
    "for i in 1:N\n",
    "    wait(tasks[i])\n",
    "end\n",
    "\n",
    "h = fit(Histogram, times.data, 1:1:N+1)\n",
    "barplot(h.weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c2c650a",
   "metadata": {},
   "source": [
    "## Wątki\n",
    "\n",
    "Przedstawione zadania nie są równoległe, bo używają pojedynczego wątku i wspólnej pamięci. Dlatego ich użycie nie przyspiesza np. obliczeń numerycznych, i są stosowane przede wszystkim do zadań I/O, aby nie blokować wykonywania innych części programu.\n",
    "\n",
    "Prawdziwą równoległość umożliwiają wątki (threads). Domyślnie Julia startuje tylko z jednym wątkiem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "115a4ffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "Threads.nthreads()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5989119d",
   "metadata": {},
   "source": [
    "Ale uruchomiona z flagą -t/--threads może mieć ich więcej\n",
    "```\n",
    "$ julia --threads 4\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27475d4a",
   "metadata": {},
   "source": [
    "W przypadku notatnika Jupyter trzeba zdefiniować nowy rdzeń np. z 4 wątkami"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebd16dd3",
   "metadata": {},
   "source": [
    "```\n",
    "julia> using IJulia\n",
    "julia> IJulia.installkernel(\"Julia 4 Threads\", env=Dict(\"JULIA_NUM_THREADS\" => \"4\",))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "054e2aaa",
   "metadata": {},
   "source": [
    "Używanie wątków oprócz oczywistych korzyści sprawia także dodatkowe zobowiązania takie jak zapewnienie, że nie występuje wyścig do danych (data-race) potencjalne zakleszczenie (deadlock), zagłodzenie (starvation), oraz czytanie danych, które mogą być manipulowane przez wiele wątków jest bezpieczne.\n",
    "\n",
    "Aby zapewnić brak negatywnych zjawisk istnieje kilka mechanizów - blokady oraz operacje atomistyczne.\n",
    "\n",
    "Do ilustracji wyścigu użyjemy jednego z najprostszych mechanizów wielowąkowych - makra `@threads`, które automatycznie zrównolegla pętle `for`. W przykładzie używamy tablicy jednoelementowej ze względu na sposób przekazywania przez wskaźnik."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52d2c8d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wersja jednowątkowa\n",
    "s = zeros(Int64, 1)\n",
    "for i in 1:1_000_000\n",
    "    s[1] += 1\n",
    "end\n",
    "println(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49ff7667",
   "metadata": {},
   "source": [
    "W przypadku prostej pętli nie mamy żadnego problemu z oczywistem wynikiem dodawania jedynki milion razy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e8e3336",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wielowątkowa\n",
    "s = zeros(Int64, 1)\n",
    "Threads.@threads for i in 1:1_000_000\n",
    "    s[1] += 1\n",
    "end\n",
    "println(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac0d2346",
   "metadata": {},
   "source": [
    "Naiwna wersja wielowątkowa po prostu dodaje makro przed pętlą for, ale nie dba o wystąpienie wyścigu: wątki wykonują operację dodawania w 3 krokach (pobierz, dodaj, wpisz)\n",
    "\n",
    "| Wątek i operacja | Wartość |\n",
    "-------------------|---------|\n",
    "| 1: pobiera 0     |      0    |\n",
    "| 2: pobiera 0     |      0    |\n",
    "| 1: dodaje 0+1    |      0    |\n",
    "| 2: dodaje 0+1    |      0    |\n",
    "| 1: wpisuje 1     |      1    |\n",
    "| 2: wpisuje 1     |      1    |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c9afc81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Atomistyczne\n",
    "s = Threads.Atomic{Int}(0)\n",
    "Threads.@threads for i in 1:1_000_000\n",
    "    Threads.atomic_add!(s, 1)\n",
    "end\n",
    "println(s.value)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e235645",
   "metadata": {},
   "source": [
    "Operacja atomistyczna (jednostkowa) zapewnia, że cała czynność musi być wykonana w jednym kroku (choć na poziomie instrukcji procesora nadal musi być ich kilka). Dzięki temu dodawanie atomistyczne (atomic_add!) daje dobry wynik."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c511d059",
   "metadata": {},
   "source": [
    "Ten sam efekt można osiągnąć stosując blokadę (lock), która zapewnia, że tylko jeden wątek wykonuje krytyczną operację jednocześnie. Oczywiście w tym prostym przypadku operacja atomistyczna jest prostsza w implementacji, ale mechanizm blokad jest znacznie bardziej elastyczny i w bardziej skomplikowanym przypadku może być niezbędny.\n",
    "\n",
    "Podstawowy schemat użycia blokady to:\n",
    "```\n",
    "    lock(lk)\n",
    "    try\n",
    "        # operacja\n",
    "    finally\n",
    "        unlock(lk)\n",
    "    end\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f5b2886",
   "metadata": {},
   "outputs": [],
   "source": [
    "function increase(s, x, lk)\n",
    "    lock(lk)\n",
    "    try\n",
    "        s[1] += x\n",
    "    finally\n",
    "        unlock(lk)\n",
    "    end\n",
    "end\n",
    "\n",
    "rl = ReentrantLock()\n",
    "s = zeros(Int64, 1)\n",
    "Threads.@threads for i in 1:1_000_000\n",
    "    increase(s, 1, rl)\n",
    "end\n",
    "println(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfa0bbf9",
   "metadata": {},
   "source": [
    "Makro `@threads` działa tylko na pętle `for`. W ogólnym przypadku uruchamianie wątków jest bardzo podobne do uruchamiania zadań. Makro `@spawn` jest odpowiednikiem `@async`. Pozostałe mechanizmy (wait, channel, itp.) można używać jak w programowaniu asynchronicznym. Różnicą jest oczywiście uruchamianie wątków na osobnych wątkach CPU i lepsze wykorzystanie mocy obliczeniowych komputera."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ac490e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "using GRUtils\n",
    "using StatsBase\n",
    "\n",
    "function worker(id, data, stop)\n",
    "    while true\n",
    "        if isready(stop)\n",
    "            break\n",
    "        end\n",
    "        for i in 1:1_000_000\n",
    "            rand()\n",
    "        end\n",
    "        put!(data, id)\n",
    "    end\n",
    "    println(\"W-\", id, \" done\")\n",
    "end\n",
    "\n",
    "sigstop = Channel{Bool}(1)\n",
    "times = Channel{Int64}(Inf)\n",
    "tasks = Array{Task, 1}()\n",
    "N = 4\n",
    "\n",
    "println(\"Start\")\n",
    "\n",
    "for i in 1:N\n",
    "    push!(tasks, Threads.@spawn worker(i, times, sigstop))\n",
    "end\n",
    "\n",
    "sleep(5)\n",
    "println(\"Stop send\")\n",
    "put!(sigstop, true)\n",
    "\n",
    "for i in 1:N\n",
    "    wait(tasks[i])\n",
    "end\n",
    "\n",
    "h = fit(Histogram, times.data, 1:1:N+1)\n",
    "barplot(h.weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79c47791",
   "metadata": {},
   "source": [
    "## Przetwarzanie wieloprocesorowe i rozproszone\n",
    "\n",
    "Pełne wykorzystanie zasobów współczesnych komputerów posiadających wiele procesorów, czy klastrów komputerów lub wręcz wykorzystanie rozproszonych fizycznie komputerów wymaga jeszcze innego podejścia, w którym nie tylko CPU, ale i pamięć RAM jest rozdzielona pomiędzy procesory. Rodzi to dodatkowe problemy w programowaniu i zasadniczo różni się ono od tego co widzieliśmy dotychczas.\n",
    "\n",
    "Aby uruchomić Julię korzystając z wielu procesów podajemy parametr `-p n`, co automatycznie ładuje bibliotekę `Distributed` i `n` dodatkowych procesów. Oczywiście sensownie jest ustalić tę wielkość na nie więcej niż liczba fizycznych rdzeni procesora. Każdy proces ma swój indetyfikator zaczynający się od 1 (jeżeli uruchomiona jest interaktywna sesja, to zawsze ma numer 1). Numer można sprawdzić przez `myid()`, a listę wszystkich \"robotników\" (workers - procesy poza głównym) przez `workers()`. Dodawać procesy można także ładując bibliotekę i używając funkcji `addprocs`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40d8427e",
   "metadata": {},
   "outputs": [],
   "source": [
    "using Distributed\n",
    "\n",
    "println(\"myid: \", myid())\n",
    "println(workers())\n",
    "println(nprocs())\n",
    "println(nworkers())\n",
    "\n",
    "addprocs(2)\n",
    "println(workers())\n",
    "println(nprocs())\n",
    "println(nworkers())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad35d3eb",
   "metadata": {},
   "source": [
    "Podstawową niskopoziomową strukturą jest uruchomienie wyrażenia (funkcji, itp.) na procesie `n` poprzez `remotecall`. Zwraca ono obiekt `Future`, który jest zastępczym obiektem dla wyniku obliczeń, które mają nieznany stan i czas zakończenia.\n",
    "\n",
    "```\n",
    "remotecall(funkcja, worker_id, argumenty...)\n",
    "```\n",
    "\n",
    "Funkcja `fetch` czeka na zakończenie procesu i czyta zwracaną wartość."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f55ee25a",
   "metadata": {},
   "outputs": [],
   "source": [
    "r = remotecall(rand, 2, Int64, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4183d865",
   "metadata": {},
   "outputs": [],
   "source": [
    "fetch(r)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94b2dc7a",
   "metadata": {},
   "source": [
    "Makro `@spawnat p wyrażenie`  uruchamia wyrażenie na procesie `p`, zamiast numeru można użyć `:any` i wtedy proces zostanie wybrany automatycznie."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62470169",
   "metadata": {},
   "outputs": [],
   "source": [
    "r = @spawnat :any rand(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87dcfe9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fetch(r)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9a5740c",
   "metadata": {},
   "source": [
    "Kod który uruchamiamy musi być dostępny dla wszystkich procesów. Jeżeli zdefinujemy np. jakąś funkcję w sesji interaktywnej (proces 1), to inne procesy nie będą jej znały"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1527eaeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "function f()\n",
    "    rand(10)\n",
    "end\n",
    "\n",
    "r = @spawnat 2 f()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "514b0aa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "fetch(r)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a535b9a0",
   "metadata": {},
   "source": [
    "Makro `@everywhere` pozwala na załadowanie wyrażenia na wszystkich procesach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "305ae667",
   "metadata": {},
   "outputs": [],
   "source": [
    "@everywhere function f()\n",
    "                rand(10)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c98435bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "r = @spawnat 2 f()\n",
    "fetch(r)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17b917a9",
   "metadata": {},
   "source": [
    "Ponieważ każdy proces ma swoją pamięć RAM, czasami konieczne jest przesyłanie danych pomiędzy procesami. Jest to zwykle wąskie gardło obliczeń równoległych i powinno być minimalizowane. Najlepiej jest tak zorganizować algorytm czy kod, aby zwracał on wynik obliczeń i minimalizował przesyłanie danych.\n",
    "\n",
    "Odpowiednikiem kanałów jest `RemoteChannel`. Inne struktury też mają swoje odpowiedniki np. `SharedArrays`. Użyjemy tych dwóch struktur w przykładzie poniżej."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4af39f36",
   "metadata": {},
   "source": [
    "## Przykład \n",
    "\n",
    "Spróbujemy zbudować następujący wieloprocesorowy program, w którym dane będą generowane dane przez niezależne procesy, a trzeci proces będzie zajęty rysowaniem wykresu (histogramu). Jeden generator będzie losował szum, drugi rozkład normalny. Obydwa będą wpisywały wyniki do współdzielonej tablicy. Użyjemy podobnego mechanizmu zatrzymywania co wcześniej, poprzez wysłanie sygnału do wszystkich procesów."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "437f24fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "using Distributed\n",
    "using SharedArrays\n",
    "using GRUtils\n",
    "\n",
    "addprocs(2)\n",
    "\n",
    "@everywhere using Distributions\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4918588",
   "metadata": {},
   "source": [
    "Generator szumu będzie produkował dane z rozkładu płaskiego w całym zakresie histogramu. Zwróci na koniec liczbę punktów, którą wpisał do histogramu (będziemy mogli sprawdzić czy nie straciliśmy danych)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b08871c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "@everywhere function generator_noise!(sigstop, histogram)\n",
    "    println(\"Starting noise generator \", myid())\n",
    "    nmax = length(histogram)\n",
    "    n = 0\n",
    "    while true\n",
    "        if isready(sigstop)\n",
    "            break\n",
    "        end\n",
    "        i = round(Int64, rand() * nmax, RoundUp)\n",
    "        if 0 < i <= nmax\n",
    "            histogram[i] += 1\n",
    "            n += 1\n",
    "        end\n",
    "    end\n",
    "    println(\"Noise generator done\")\n",
    "    n\n",
    "end\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cda2a61",
   "metadata": {},
   "source": [
    "Drugi generator będzie produkował dane z rozkładu normalnego"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f57f2511",
   "metadata": {},
   "outputs": [],
   "source": [
    "@everywhere function generator_peak!(sigstop, histogram)\n",
    "    println(\"Starting peak generator \", myid())\n",
    "    nmax = length(histogram)\n",
    "    normal = Normal(nmax / 2, 100.0)\n",
    "    n = 0\n",
    "    while true\n",
    "        if isready(sigstop)\n",
    "            break\n",
    "        end\n",
    "        i = round(Int64, rand(normal), RoundUp)\n",
    "        if 0 < i <= nmax\n",
    "            histogram[i] += 1\n",
    "            n += 1\n",
    "        end\n",
    "    end\n",
    "    println(\"Peak generator done\")\n",
    "    n\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cd416ab",
   "metadata": {},
   "source": [
    "Potrzebujemy także funkcji rysującej bieżący histogram. Oprócz danych i sygnałów stopu zdefinujemy co ile sekund wykres ma się odświeżać."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94c37905",
   "metadata": {},
   "outputs": [],
   "source": [
    "function plotter(sigstop, histogram, fig, update)\n",
    "    println(\"Starting plotter \", myid())\n",
    "\n",
    "    gcf(fig)\n",
    "    while true\n",
    "        if isready(sigstop)\n",
    "            break\n",
    "        end\n",
    "        stairs(histogram)\n",
    "        xlim(0, 16384)\n",
    "        xticks(1000, 5)\n",
    "        ylim(0, maximum(histogram) + 5)\n",
    "        display(gcf())\n",
    "        sleep(update)\n",
    "    end\n",
    "    println(\"Plotter done\")\n",
    "end\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a7aa082",
   "metadata": {},
   "source": [
    "Zdefinujemy teraz sygnał stopujący (RemoteChannel), histogram (SharedArray) i wykres. Funckja rysująca będzie zadaniem, bo ma odświeżać wykres tylko co jakiś czas. Zmienna trun zdefinuje czas działania w sekundach, po jakim wysłany zostanie sygnał stopujący."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62430b83",
   "metadata": {},
   "outputs": [],
   "source": [
    "trun = 10\n",
    "\n",
    "sigstop = RemoteChannel(()->Channel{Bool}(1))\n",
    "histogram = SharedArray{Int64, 1}(16384)\n",
    "\n",
    "#fig = Figure((800, 600), \"pix\")\n",
    "#display(gcf())\n",
    "\n",
    "#p = @task plotter(sigstop, histogram, fig, 0.1)\n",
    "#schedule(p)\n",
    "\n",
    "gn = @spawnat :any generator_noise!(sigstop, histogram)\n",
    "gp = @spawnat :any generator_peak!(sigstop, histogram)\n",
    "\n",
    "sleep(trun)\n",
    "put!(sigstop, true)\n",
    "\n",
    "sn = fetch(gn)\n",
    "sp = fetch(gn)\n",
    "println(sum(histogram), \" events in histogram\")\n",
    "println(sn + sp, \" events generated\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9e47437",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(histogram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cacb2d95",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 4 Threads 1.7.3",
   "language": "julia",
   "name": "julia-4-threads-1.7"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
